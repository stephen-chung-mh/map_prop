[DEFAULT]

# General parameters
name = Cartpole # Name of the run
max_eps = 1000 # Number of episode per run
n_run = 10 # Number of runs

# Task parameters
batch_size = 1 # Batch size
env_name = CartPole-v1 # Environment name
gamma = 0.98 # Discount rate

hidden = [64,32] # Number of hidden units on each layer
critic_l_type = 0 # Activation function for hidden units in critic network; 0 for softplus and 1 for ReLu
actor_l_type = 0 # Activation function for hidden units in actor network; 0 for softplus and 1 for ReLu
temp = 2 # Temperature for actor network if applicable

critic_var = [0.03, 0.1, 0.1] # Variance in the normal distribution of critic network's layer
critic_update_adj = 0.5 # Step size for minimizing the energy of critic network equals to the layer's variance multiplied by this constant
critic_lambda_ = 0.95 # Trace decay rate for critic network

actor_var = [0.03, 0.1, 0.1] # Variance in the normal distribution of actor network's layer
actor_update_adj = 0.5 # Step size for minimizing the energy of actor network equals to the layer's variance multiplied by this constant
actor_lambda_ = 0.95 # Trace decay rate for actor network

map_grad_ascent_steps = 20 # number of step for minimizing the energy
reward_lim = -1 # whether limit the size of reward; negative for no limitation

critic_lr_st = [0.02,0.00002,0.000002] # Learning rate for each critic network's layer at the beginning
critic_lr_end = [0.002,0.000002,0.0000002] # Learning rate for each critic network's layer at the beginning
actor_lr_st = [0.01,0.00001,0.000001] # Learning rate for each actor network's layer at the end
actor_lr_end = [0.001,0.000001,0.00000001] # Learning rate for each actor network's layer at the end
end_t = 50000 # Number of step to reach the final learning rate (linear interpolation for in-between steps)

[USER]
